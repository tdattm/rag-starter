{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "294dc658",
   "metadata": {},
   "source": [
    "# 03_answer_with_gemini.ipynb — Tạo câu trả lời bằng Gemini từ top-k context\n",
    "Notebook này minh hoạ cách:\n",
    "1) Lấy **top-k context** từ Chroma (dense hoặc hybrid),\n",
    "2) Gọi **Gemini** (thông qua `src/llm/gemini_client.py`) để sinh câu trả lời **chỉ dựa trên ngữ cảnh**,\n",
    "3) Trả lời kèm **citation (tr. X, Chương: Y)**.\n",
    "\n",
    "> ⚠️ Yêu cầu:\n",
    "> - Bạn đã cài `google-generativeai` và có `GOOGLE_API_KEY` trong `.env`.\n",
    "> - Đã ingest dữ liệu vào collection (VD: `prisoners_of_geography`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31165c9a",
   "metadata": {},
   "source": [
    "## 0. Cấu hình\n",
    "- `COLLECTION_NAME`: tên collection.\n",
    "- `TOP_K`: số context đưa vào Gemini.\n",
    "- `MODEL_NAME`: model Gemini muốn dùng (ví dụ `gemini-1.5-flash` để nhanh/tiết kiệm).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20a588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = 'prisoners_of_geography'\n",
    "TOP_K = 5\n",
    "MODEL_NAME = 'gemini-1.5-flash'  # hoặc 'gemini-1.5-pro' nếu bạn muốn chất lượng cao hơn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e4c08f",
   "metadata": {},
   "source": [
    "## 1. Nạp `.env` & import\n",
    "- Load biến môi trường (đặc biệt `GOOGLE_API_KEY`).\n",
    "- Import client Chroma và hàm gọi Gemini.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c39dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()\n",
    "\n",
    "import os\n",
    "from src.utils.chroma_client import get_chroma_collection\n",
    "from src.llm.gemini_client import answer_with_context_gemini\n",
    "\n",
    "# Kiểm tra đã có GOOGLE_API_KEY chưa (nếu gọi Gemini)\n",
    "api = os.getenv('GOOGLE_API_KEY', '')\n",
    "assert api, \"GOOGLE_API_KEY trống. Điền key vào .env trước khi chạy cell gọi Gemini.\"\n",
    "\n",
    "col = get_chroma_collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab0cba9",
   "metadata": {},
   "source": [
    "## 2. Chuẩn bị câu hỏi & lấy top-k context (dense)\n",
    "- Sử dụng `collection.query(query_texts=[q], n_results=TOP_K)`.\n",
    "- Chuyển đổi `documents + metadatas` → danh sách context phù hợp cho `answer_with_context_gemini`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcafc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đặt câu hỏi tại đây\n",
    "question = \"Ví dụ: Địa hình và vị trí của Nga ảnh hưởng thế nào đến chiến lược của nước này?\"  # thay bằng câu của bạn\n",
    "\n",
    "result = col.query(query_texts=[question], n_results=TOP_K)\n",
    "docs = result['documents'][0]\n",
    "metas = result['metadatas'][0]\n",
    "\n",
    "contexts = []\n",
    "for d, m in zip(docs, metas):\n",
    "    contexts.append({\n",
    "        'text': d,\n",
    "        'page': f\"{m.get('start_page')}→{m.get('end_page')}\",\n",
    "        'chapter': m.get('chapter', '')\n",
    "    })\n",
    "\n",
    "len(contexts), contexts[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ce1070",
   "metadata": {},
   "source": [
    "## 3. Gọi Gemini để sinh câu trả lời có citation\n",
    "- Hàm `answer_with_context_gemini(question, contexts, model_name)` sẽ:\n",
    "  - Chuẩn hoá ngữ cảnh, \n",
    "  - Gửi prompt hệ thống **\"chỉ dùng ngữ cảnh\"**,\n",
    "  - Trả về câu trả lời kèm citation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a341d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = answer_with_context_gemini(question, contexts, model_name=MODEL_NAME)\n",
    "print(answer if answer else \"Không nhận được câu trả lời từ Gemini (kiểm tra key/hạn mức).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018c76ce",
   "metadata": {},
   "source": [
    "## 4. (Tuỳ chọn) Hybrid trước khi gọi Gemini\n",
    "- Nếu bạn đã có `hybrid_retrieve`, có thể dùng hybrid để lấy context sau đó mới gọi Gemini.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb2894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from src.rag_pipeline import hybrid_retrieve\n",
    "    hits = hybrid_retrieve(question, k_dense=TOP_K, k_sparse=TOP_K, collection_name=COLLECTION_NAME)\n",
    "    # Quy đổi sang contexts cho Gemini\n",
    "    hybrid_contexts = []\n",
    "    for h in hits:\n",
    "        m = h.get('meta', {})\n",
    "        hybrid_contexts.append({\n",
    "            'text': h['text'],\n",
    "            'page': f\"{m.get('start_page')}→{m.get('end_page')}\" if m else '',\n",
    "            'chapter': m.get('chapter', '') if m else ''\n",
    "        })\n",
    "    print(f\"Hybrid contexts: {len(hybrid_contexts)} đoạn\")    \n",
    "    answer2 = answer_with_context_gemini(question, hybrid_contexts, model_name=MODEL_NAME)\n",
    "    print(\"\\n---\\nCâu trả lời (Hybrid):\\n\", answer2 if answer2 else \"Không nhận được câu trả lời từ Gemini.\")\n",
    "except Exception as e:\n",
    "    print('Bỏ qua hybrid do lỗi hoặc chưa triển khai:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0347c4f3",
   "metadata": {},
   "source": [
    "---\n",
    "### Mẹo\n",
    "- Nếu câu trả lời dài dòng hoặc có dấu hiệu \"bịa\", hãy giảm `TOP_K`, tăng chất lượng context (đặt câu hỏi cụ thể hơn), và đảm bảo prompt hệ thống yêu cầu **chỉ dựa trên context**.\n",
    "- Kiểm tra lại `eval/chapter_map.json` để citation hiển thị tên chương chính xác.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
